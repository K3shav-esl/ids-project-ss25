{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11402313",
   "metadata": {},
   "source": [
    "# IDS Challenge\n",
    "# Teilprojekt 03: Inverse Roboterkinematik\n",
    "## Ergebnisse\n",
    "\n",
    "### Gruppe: ___\n",
    "### Tutor: ___\n",
    "\n",
    "Dies ist Ihr Arbeitsbereich mit einigen bereitgestellten Funktionen. Lesen Sie die Aufgabenbeschreibung und implementieren Sie alle Lösungen hier. Lesen Sie zuerst die Datei „README.ipynb“."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32281047-ebc8-4a07-8d9c-f3db1c448401",
   "metadata": {},
   "source": [
    "# Szenendefinition und weitere Funktionen\n",
    "\n",
    "Führen Sie die folgenden Schritte aus, um die untenstehenden Definitionen und Funktionen verfügbar zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f18f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import display, HTML\n",
    "import math\n",
    "\n",
    "# --- Global Parameters for the Robot and Environment ---\n",
    "L1 = 6.0  # Length of the first robot arm link\n",
    "L2 = 6.0  # Length of the second robot arm link\n",
    "L3 = 1.0  # Length of the rope/link holding the gripper attachment point\n",
    "\n",
    "# Robot Gripper Parameters\n",
    "GRIPPER_RADIUS = 0.5 # Radius of the robot's gripper (blue sphere/circle for collision)\n",
    "\n",
    "# Manipulable Object Parameters (the one to be picked and placed)\n",
    "MANIPULABLE_OBJECT_WIDTH = 2 * GRIPPER_RADIUS\n",
    "MANIPULABLE_OBJECT_HEIGHT = 2 * GRIPPER_RADIUS\n",
    "\n",
    "# --- MODIFIED: Obstacles reconfigured to create a horizontal gap ---\n",
    "# This setup forces the robot to move through the gap between the two obstacles.\n",
    "OBSTACLES = [\n",
    "    # Lower barrier (floor of the gap)\n",
    "    {\"x_center\": 4.5, \"width\": 1.0, \"height\": 3.5, \"y_min\": 0.0},\n",
    "    {\"x_center\": 7.0, \"width\": 1.0, \"height\": 3.0, \"y_min\": 0.0},\n",
    "    # Upper barrier (ceiling of the gap)\n",
    "    {\"x_center\": 5.0, \"width\": 2.0, \"height\": 2.0, \"y_min\": 6.5}\n",
    "]\n",
    "\n",
    "# --- Pick and Place Station Parameters ---\n",
    "PICK_STATION = {\"x_center\": 2.0, \"width\": 2.0, \"height\": 1.0, \"y_min\": 0.0}\n",
    "PLACE_STATION = {\"x_center\": 9.5, \"width\": 2.0, \"height\": 1.0, \"y_min\": 0.0}\n",
    "PICK_TARGET = np.array([2.0, 1.0])\n",
    "PLACE_TARGET = np.array([9.5, 1.0]) \n",
    "\n",
    "# Initial position of the manipulable object (bottom-center) on the pick station\n",
    "INITIAL_MANIPULABLE_OBJECT_POS = np.array([PICK_STATION[\"x_center\"], PICK_STATION[\"y_min\"] + PICK_STATION[\"height\"]])\n",
    "\n",
    "# --- Global State Variables for Animation ---\n",
    "# These are used to store the pre-calculated path and track the state during the animation.\n",
    "alpha_path = []\n",
    "beta_path = []\n",
    "x_path_dense = []\n",
    "y_path_dense = []\n",
    "object_is_picked = False\n",
    "animation_running = True\n",
    "# We will draw the object's position based on this variable, which is updated each frame.\n",
    "current_manipulable_object_pos = INITIAL_MANIPULABLE_OBJECT_POS.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1071f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_direct_kinematics(alpha, beta):\n",
    "    \"\"\"\n",
    "    Calculates forward kinematics of the two-link robot arm using the\n",
    "    same angle convention as inverse kinematics:\n",
    "    alpha = shoulder angle q1\n",
    "    beta = elbow angle q2\n",
    "\n",
    "    Returns points P, Q, G, GC, GB as numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    # Position of joint P (end of first link)\n",
    "    P = L1 * np.array([np.cos(alpha), np.sin(alpha)])\n",
    "\n",
    "    # Position of joint Q (end of second link / arm end)\n",
    "    Q = P + L2 * np.array([np.cos(alpha + beta), np.sin(alpha + beta)])\n",
    "\n",
    "    # Position of point G (bottom of rope)\n",
    "    G = Q + L3 * np.array([0, -1])\n",
    "\n",
    "    # Position of point GC (bottom of object, first radius offset)\n",
    "    GC = G + GRIPPER_RADIUS * np.array([0, -1])\n",
    "\n",
    "    # Position of point GB (bottom of object, second radius offset)\n",
    "    GB = GC + GRIPPER_RADIUS * np.array([0, -1])\n",
    "\n",
    "    return P, Q, G, GC, GB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdbd795",
   "metadata": {},
   "source": [
    "# Visualisierung\n",
    "\n",
    "Führen Sie die folgenden Zellen aus, um die Visualisierung und Animation verfügbar zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a71391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_inverse_kinematics(target_GB):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_path_points(target_points):\n",
    "    \"\"\"\n",
    "    Converts a list of target [x, y] points into separate NumPy arrays for x and y coordinates,\n",
    "    interpolating points between targets to create a smooth path.\n",
    "    \"\"\"\n",
    "    if not target_points:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    x_coords = [target_points[0][0]]\n",
    "    y_coords = [target_points[0][1]]\n",
    "\n",
    "    for i in range(len(target_points) - 1):\n",
    "        d = np.sqrt((target_points[i][0] - target_points[i+1][0])**2 + \\\n",
    "                    (target_points[i][1] - target_points[i+1][1])**2)\n",
    "        num_points = max(2, math.ceil(d / (GRIPPER_RADIUS / 2)))\n",
    "        x_coords.extend(np.linspace(target_points[i][0], target_points[i+1][0], num_points + 1)[1:])\n",
    "        y_coords.extend(np.linspace(target_points[i][1], target_points[i+1][1], num_points + 1)[1:])\n",
    "\n",
    "    return np.array(x_coords), np.array(y_coords)\n",
    "\n",
    "def check_collision_circle_rect(circle_center, circle_radius, rect_x_center, rect_width, rect_height, rect_y_min_val):\n",
    "    \"\"\"\n",
    "    Checks for collision between a circle and a rectangle.\n",
    "    \"\"\"\n",
    "    rect_x_min = rect_x_center - rect_width / 2\n",
    "    rect_x_max = rect_x_center + rect_width / 2\n",
    "    rect_y_min = rect_y_min_val\n",
    "    rect_y_max = rect_y_min_val + rect_height\n",
    "\n",
    "    closest_x = np.clip(circle_center[0], rect_x_min, rect_x_max)\n",
    "    closest_y = np.clip(circle_center[1], rect_y_min, rect_y_max)\n",
    "\n",
    "    distance_sq = (circle_center[0] - closest_x)**2 + \\\n",
    "                  (circle_center[1] - closest_y)**2\n",
    "\n",
    "    return distance_sq < circle_radius**2\n",
    "\n",
    "def intersect_segments(p1, p2, p3, p4):\n",
    "    \"\"\"\n",
    "    Checks if two line segments (p1,p2) and (p3,p4) intersect.\n",
    "    \"\"\"\n",
    "    def orientation(p, q, r):\n",
    "        val = (q[1] - p[1]) * (r[0] - q[0]) - \\\n",
    "              (q[0] - p[0]) * (r[1] - q[1])\n",
    "        if val == 0: return 0\n",
    "        return 1 if val > 0 else 2\n",
    "\n",
    "    def on_segment(p, q, r):\n",
    "        return (q[0] <= max(p[0], r[0]) and q[0] >= min(p[0], r[0]) and\n",
    "                q[1] <= max(p[1], r[1]) and q[1] >= min(p[1], r[1]))\n",
    "\n",
    "    o1 = orientation(p1, p2, p3)\n",
    "    o2 = orientation(p1, p2, p4)\n",
    "    o3 = orientation(p3, p4, p1)\n",
    "    o4 = orientation(p3, p4, p2)\n",
    "\n",
    "    if o1 != 0 and o2 != 0 and o3 != 0 and o4 != 0 and o1 != o2 and o3 != o4:\n",
    "        return True\n",
    "    if o1 == 0 and on_segment(p1, p3, p2): return True\n",
    "    if o2 == 0 and on_segment(p1, p4, p2): return True\n",
    "    if o3 == 0 and on_segment(p3, p1, p4): return True\n",
    "    if o4 == 0 and on_segment(p3, p2, p4): return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def check_line_rect_collision(p1, p2, rect_x_center, rect_width, rect_height, rect_y_min_val):\n",
    "    \"\"\"\n",
    "    Checks for collision between a line segment (p1, p2) and a rectangle.\n",
    "    \"\"\"\n",
    "    rect_x_min = rect_x_center - rect_width / 2\n",
    "    rect_x_max = rect_x_center + rect_width / 2\n",
    "    rect_y_min = rect_y_min_val\n",
    "    rect_y_max = rect_y_min_val + rect_height\n",
    "\n",
    "    if (rect_x_min <= p1[0] <= rect_x_max and rect_y_min <= p1[1] <= rect_y_max) or \\\n",
    "       (rect_x_min <= p2[0] <= rect_x_max and rect_y_min <= p2[1] <= rect_y_max):\n",
    "        return True\n",
    "\n",
    "    rect_corners = [\n",
    "        np.array([rect_x_min, rect_y_min]),\n",
    "        np.array([rect_x_max, rect_y_min]),\n",
    "        np.array([rect_x_max, rect_y_max]),\n",
    "        np.array([rect_x_min, rect_y_max])\n",
    "    ]\n",
    "\n",
    "    if intersect_segments(p1, p2, rect_corners[0], rect_corners[1]): return True\n",
    "    if intersect_segments(p1, p2, rect_corners[1], rect_corners[2]): return True\n",
    "    if intersect_segments(p1, p2, rect_corners[2], rect_corners[3]): return True\n",
    "    if intersect_segments(p1, p2, rect_corners[3], rect_corners[0]): return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def robot_draw(ax, alpha, beta, current_manipulable_object_pos_for_drawing):\n",
    "    \"\"\"\n",
    "    Draws the robot, obstacles, pick/place stations, and the manipulable object onto the provided axes.\n",
    "    \"\"\"\n",
    "    # Clear previous drawings from the axis\n",
    "    ax.clear()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    all_x_coords = [obs[\"x_center\"] + obs[\"width\"]/2 for obs in OBSTACLES] + \\\n",
    "                   [PICK_STATION[\"x_center\"] + PICK_STATION[\"width\"]/2,\n",
    "                    PLACE_STATION[\"x_center\"] + PLACE_STATION[\"width\"]/2]\n",
    "    max_x_val = max(all_x_coords)\n",
    "\n",
    "    all_y_coords = [obs[\"y_min\"] + obs[\"height\"] for obs in OBSTACLES] + \\\n",
    "                   [PICK_STATION[\"y_min\"] + PICK_STATION[\"height\"],\n",
    "                    PLACE_STATION[\"y_min\"] + PLACE_STATION[\"height\"]]\n",
    "    max_y_val = max(all_y_coords)\n",
    "\n",
    "    ax.set_xlim(-L1, max(L1 + L2 + 2, max_x_val + 2.0))\n",
    "    ax.set_ylim(-1.0, max(L1 + L2 + 2, max_y_val + 2.0))\n",
    "\n",
    "    baseline_x = np.array([-0.5, max(max_x_val + 2.0, 12.0)])\n",
    "    baseline_y = np.array([0.0, 0.0])\n",
    "    ax.plot(baseline_x, baseline_y, '-k')\n",
    "\n",
    "    NORMAL_LINK_COLOR = [0.2, 0.2, 0.8]\n",
    "    COLLISION_COLOR = [1.0, 0.0, 0.0]\n",
    "    STATION_COLOR = [0.6, 0.6, 0.6]\n",
    "    MANIPULABLE_OBJECT_COLOR = [1.0, 0.0, 0.0]\n",
    "\n",
    "    link1_color = NORMAL_LINK_COLOR\n",
    "    link2_color = NORMAL_LINK_COLOR\n",
    "    link3_color = NORMAL_LINK_COLOR\n",
    "    robot_gripper_color = [0.0, 0.0, 1.0]\n",
    "\n",
    "    collided_obstacle_indices = set()\n",
    "    overall_collision_detected = False\n",
    "\n",
    "    O = np.array([0.0, 0.0])\n",
    "    P, Q, G, GC, GB_fk = robot_direct_kinematics(alpha, beta)\n",
    "\n",
    "    for idx, obs in enumerate(OBSTACLES):\n",
    "        if check_collision_circle_rect(GC, GRIPPER_RADIUS, obs[\"x_center\"], obs[\"width\"], obs[\"height\"], obs[\"y_min\"]):\n",
    "            robot_gripper_color = COLLISION_COLOR\n",
    "            collided_obstacle_indices.add(idx)\n",
    "            overall_collision_detected = True\n",
    "        if check_line_rect_collision(O, P, obs[\"x_center\"], obs[\"width\"], obs[\"height\"], obs[\"y_min\"]):\n",
    "            link1_color = COLLISION_COLOR\n",
    "            collided_obstacle_indices.add(idx)\n",
    "            overall_collision_detected = True\n",
    "        if check_line_rect_collision(P, Q, obs[\"x_center\"], obs[\"width\"], obs[\"height\"], obs[\"y_min\"]):\n",
    "            link2_color = COLLISION_COLOR\n",
    "            collided_obstacle_indices.add(idx)\n",
    "            overall_collision_detected = True\n",
    "        if check_line_rect_collision(Q, G, obs[\"x_center\"], obs[\"width\"], obs[\"height\"], obs[\"y_min\"]):\n",
    "            link3_color = COLLISION_COLOR\n",
    "            collided_obstacle_indices.add(idx)\n",
    "            overall_collision_detected = True\n",
    "\n",
    "    for idx, obs in enumerate(OBSTACLES):\n",
    "        obstacle_x = obs[\"x_center\"] + obs[\"width\"] / 2 * np.array([-1.0, 1.0, 1.0, -1.0, -1.0])\n",
    "        obstacle_y = np.array([obs[\"y_min\"], obs[\"y_min\"], obs[\"y_min\"] + obs[\"height\"], obs[\"y_min\"] + obs[\"height\"], obs[\"y_min\"]])\n",
    "        obstacle_fill_color = COLLISION_COLOR if idx in collided_obstacle_indices else [0.0, 1.0, 0.0]\n",
    "        ax.fill_between(obstacle_x, obstacle_y, facecolor=obstacle_fill_color, alpha=0.7)\n",
    "        ax.plot(obstacle_x, obstacle_y, '-k')\n",
    "\n",
    "    pick_x = PICK_STATION[\"x_center\"] + PICK_STATION[\"width\"] / 2 * np.array([-1.0, 1.0, 1.0, -1.0, -1.0])\n",
    "    pick_y = np.array([PICK_STATION[\"y_min\"], PICK_STATION[\"y_min\"], PICK_STATION[\"y_min\"] + PICK_STATION[\"height\"], PICK_STATION[\"y_min\"] + PICK_STATION[\"height\"], PICK_STATION[\"y_min\"]])\n",
    "    ax.fill_between(pick_x, pick_y, facecolor=STATION_COLOR, alpha=0.8)\n",
    "    ax.plot(pick_x, pick_y, '-k')\n",
    "    ax.text(PICK_STATION[\"x_center\"], PICK_STATION[\"y_min\"] + PICK_STATION[\"height\"] / 2, \"PICK\",\n",
    "            horizontalalignment='center', verticalalignment='center', color='black', fontsize=10)\n",
    "\n",
    "    place_x = PLACE_STATION[\"x_center\"] + PLACE_STATION[\"width\"] / 2 * np.array([-1.0, 1.0, 1.0, -1.0, -1.0])\n",
    "    place_y = np.array([PLACE_STATION[\"y_min\"], PLACE_STATION[\"y_min\"], PLACE_STATION[\"y_min\"] + PLACE_STATION[\"height\"], PLACE_STATION[\"y_min\"] + PLACE_STATION[\"height\"], PLACE_STATION[\"y_min\"]])\n",
    "    ax.fill_between(place_x, place_y, facecolor=STATION_COLOR, alpha=0.8)\n",
    "    ax.plot(place_x, place_y, '-k')\n",
    "    ax.text(PLACE_STATION[\"x_center\"], PLACE_STATION[\"y_min\"] + PLACE_STATION[\"height\"] / 2, \"PLACE\",\n",
    "            horizontalalignment='center', verticalalignment='center', color='black', fontsize=10)\n",
    "\n",
    "    rect_x_coords = current_manipulable_object_pos_for_drawing[0] + MANIPULABLE_OBJECT_WIDTH / 2 * np.array([-1.0, 1.0, 1.0, -1.0, -1.0])\n",
    "    rect_y_coords = np.array([current_manipulable_object_pos_for_drawing[1], current_manipulable_object_pos_for_drawing[1],\n",
    "                              current_manipulable_object_pos_for_drawing[1] + MANIPULABLE_OBJECT_HEIGHT,\n",
    "                              current_manipulable_object_pos_for_drawing[1] + MANIPULABLE_OBJECT_HEIGHT,\n",
    "                              current_manipulable_object_pos_for_drawing[1]])\n",
    "    ax.fill_between(rect_x_coords, rect_y_coords, facecolor=MANIPULABLE_OBJECT_COLOR, alpha=0.9)\n",
    "    ax.plot(rect_x_coords, rect_y_coords, '-k')\n",
    "\n",
    "    ax.plot(np.array([O[0], P[0]]), np.array([O[1], P[1]]), color=link1_color)\n",
    "    ax.plot(np.array([P[0], Q[0]]), np.array([P[1], Q[1]]), color=link2_color)\n",
    "    ax.plot(np.array([Q[0], G[0]]), np.array([Q[1], G[1]]), color=link3_color)\n",
    "\n",
    "    t = np.linspace(0.0, 2 * np.pi, 100)\n",
    "    circle_x = GC[0] + GRIPPER_RADIUS * np.cos(t)\n",
    "    circle_y = GC[1] + GRIPPER_RADIUS * np.sin(t)\n",
    "    ax.fill_between(circle_x, circle_y, facecolor=robot_gripper_color)\n",
    "    ax.plot(circle_x, circle_y, '-k')\n",
    "\n",
    "    return overall_collision_detected, GB_fk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(frame_num):\n",
    "    global object_is_picked, current_manipulable_object_pos, animation_running, ani\n",
    "\n",
    "    if not animation_running:\n",
    "        ani.event_source.stop()\n",
    "        return\n",
    "\n",
    "    # Joint angles and gripper position\n",
    "    current_alpha = alpha_path[frame_num]\n",
    "    current_beta = beta_path[frame_num]\n",
    "    _, _, _, _, GB_fk = robot_direct_kinematics(current_alpha, current_beta)\n",
    "\n",
    "    # Distance-based pick/place logic\n",
    "    if not object_is_picked and np.linalg.norm(GB_fk - PICK_TARGET) < 0.1:\n",
    "        object_is_picked = True\n",
    "        print(f\"[Frame {frame_num}] PICKED object at {GB_fk}\")\n",
    "    elif object_is_picked and np.linalg.norm(GB_fk - PLACE_TARGET) < 0.1:\n",
    "        object_is_picked = False\n",
    "        current_manipulable_object_pos = PLACE_TARGET.copy()\n",
    "        print(f\"[Frame {frame_num}] PLACED object at {PLACE_TARGET}\")\n",
    "\n",
    "    if object_is_picked:\n",
    "        current_manipulable_object_pos = GB_fk.copy()\n",
    "\n",
    "    collision, _ = robot_draw(ax, current_alpha, current_beta, current_manipulable_object_pos)\n",
    "\n",
    "    title = f\"Frame {frame_num+1}/{len(alpha_path)} | Object Picked: {object_is_picked}\"\n",
    "    if collision:\n",
    "        title = \"COLLISION DETECTED! Animation Halted.\"\n",
    "        animation_running = False\n",
    "    ax.set_title(title)\n",
    "\n",
    "def run_pick_and_place_animation(waypoints):\n",
    "    \"\"\"\n",
    "    Takes a list of waypoints and runs the full pick-and-place animation.\n",
    "    \"\"\"\n",
    "    global fig, ax, ani, alpha_path, beta_path, x_path_dense, y_path_dense\n",
    "    global object_is_picked, animation_running, current_manipulable_object_pos\n",
    "    global PICK_TARGET_FROM_WAYPOINTS, PLACE_TARGET_FROM_WAYPOINTS\n",
    "\n",
    "    # --- 1. State Initialization and Validation ---\n",
    "    alpha_path, beta_path, x_path_dense, y_path_dense = [], [], [], []\n",
    "    object_is_picked = False\n",
    "    animation_running = True\n",
    "    current_manipulable_object_pos = INITIAL_MANIPULABLE_OBJECT_POS.copy()\n",
    "\n",
    "    if len(waypoints) < 4:\n",
    "        print(\"Error: At least 4 waypoints are needed for a pick and place task (e.g., Hover-Pick, Pick, Hover-Place, Place).\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Path Pre-calculation ---\n",
    "    print(\"Interpolating path from waypoints...\")\n",
    "    x_path_dense, y_path_dense = robot_path_points(waypoints)\n",
    "\n",
    "    print(\"Pre-calculating Inverse Kinematics for the entire path...\")\n",
    "    for i in range(len(x_path_dense)):\n",
    "        target_gb = np.array([x_path_dense[i], y_path_dense[i]])\n",
    "        alpha, beta = robot_inverse_kinematics(target_gb)\n",
    "        if alpha is None:\n",
    "            print(f\"ERROR: Path is unreachable. IK failed at point {i+1} ({target_gb[0]:.2f}, {target_gb[1]:.2f}).\")\n",
    "            return\n",
    "        alpha_path.append(alpha)\n",
    "        beta_path.append(beta)\n",
    "            \n",
    "    print(\"IK pre-calculation successful. Path is reachable.\")\n",
    "\n",
    "    # --- 3. Animation Setup and Execution ---\n",
    "    print(\"Starting animation...\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ani = FuncAnimation(fig, animate, frames=len(x_path_dense), repeat=False, interval=50)\n",
    "    \n",
    "    display(HTML(ani.to_jshtml()))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de35c6",
   "metadata": {},
   "source": [
    "\n",
    "# Aufgabe 2.1 Inverse Kinematik\n",
    "\n",
    "## Bestimmung der Gelenkwinkel aus der Endeffektorposition\n",
    "\n",
    "Mit der bereits bekannten direkten Kinematik lässt sich der Roboter nur schwer an eine gewünschte Endeffektorposition bewegen. Um die Endeffektorposition $T$ des Roboters zu einer gewünschten Zielposition ($x_T$, $y_T$) zu bewegen, müssen die **Gelenkwinkel** ($\\alpha$, $\\beta$) in Abhängigkeit dieser Zielposition berechnet werden. Dieser Vorgang wird als **inverse Kinematik** bezeichnet.\n",
    "\n",
    "Die grundlegende Aufgabe besteht darin, die in der direkten Kinematik festgelegten Beziehungen umzukehren. Basierend auf der gegebenen direkten Kinematik werden die Punkte $R$, $M$ und $T$ durch einfache vertikale Offsets unter Berücksichtigung der Seillänge $L_3$ und des Objektradius $r$ vom Punkt $Q$ abgeleitet. Der erste Schritt der inversen Kinematik besteht daher darin, die Koordinaten des Punktes $Q = (Q_x, Q_y)$ vom gegebenen Zielpunkt $T$ zu bestimmen.\n",
    "\n",
    "\n",
    "### 1. Bestimmung des effektiven Zielpunkts $Q$\n",
    "\n",
    "Gegeben sind die Koordinaten des Zielpunkts $T = (x_T, y_T)$:\n",
    "\n",
    "Der vertikale Versatz von $Q$ zu $T$ beträgt $L_3 + 2r$. Um die Koordinaten von $Q$ zu bestimmen, kehren wir diesen Versatz einfach um:\n",
    "\n",
    "$$Q_x = x_T$$\n",
    "$$Q_y = y_T + (L_3 + 2r)$$\n",
    "\n",
    "Nun dient $Q = (Q_x, Q_y)$ als effektiver Zielpunkt für den Zweigelenkarm ($L_1$, $L_2$).\n",
    "\n",
    "\n",
    "### 2. Berechnung des Ellenbogenwinkels ($\\beta$)\n",
    "\n",
    "Aus der direkten Kinematik ist die Formel für die Endeffektorposition bereits bekannt:\n",
    "\n",
    "$$Q_x = L_1 \\cos(\\alpha) + L_2 \\cos(\\alpha + \\beta)$$\n",
    "$$Q_y = L_1 \\sin(\\alpha) + L_2 \\sin(\\alpha + \\beta)$$\n",
    "\n",
    "Um $\\alpha$ aus der Gleichung zu eliminieren, quadrieren und addieren wir beide Gleichungen. Das Ergebnis lautet:\n",
    "\n",
    "$$Q_x^2 + Q_y^2 = L_1^2 + L_2^2 + 2 L_1 L_2 \\cos(\\beta)$$\n",
    "\n",
    "Umformung zur Lösung von $\\cos(\\beta)$:\n",
    "\n",
    "$$\\cos(\\beta) = \\frac{Q_x^2 + Q_y^2 - L_1^2 - L_2^2}{2 L_1 L_2}$$\n",
    "\n",
    "Um $\\beta$ zu berechnen, verwenden wir die Arkustangensfunktion. Beachten Sie, dass es für einen gegebenen $\\cos(\\beta)$ im Allgemeinen zwei mögliche Lösungen für $\\beta$ gibt (entsprechend „Ellbogen hoch“ und „Ellbogen runter“). Um die Konfiguration „Ellbogen nach unten“ zu erreichen (wie sie häufig aus Stabilitäts- oder Arbeitsbereichsgründen gewünscht wird), wählen wir einen negativen Wert für $\\sin(\\beta)$:\n",
    "\n",
    "$$\\sin(\\beta) = -\\sqrt{1 - \\cos^2(\\beta)}$$\n",
    "\n",
    "Anschließend wird $\\beta$ mit der Funktion ``atan2`` berechnet, die den Winkel korrekt im entsprechenden Quadranten platziert:\n",
    "\n",
    "$$\\beta = \\text{atan2}(\\sin(\\beta), \\cos(\\beta))$$\n",
    "\n",
    "**Wichtiger Hinweis zur Erreichbarkeit**: Liegt der berechnete Wert von $\\cos(\\beta)$ außerhalb des Bereichs $[-1, 1]$, befindet sich der Zielpunkt $Q$ außerhalb der Reichweite des Roboters.\n",
    "\n",
    "\n",
    "### 3. Berechnung des Schulterwinkels ($\\alpha$)\n",
    "\n",
    "Nachdem $\\beta$ ermittelt wurde, können wir nun den Schultergelenkwinkel $\\alpha$ mithilfe eines geometrischen Ansatzes basierend auf der Dreieckskonstruktion berechnen. Berechnen Sie zunächst den Winkel des Vektors vom Ursprung zum Punkt $Q = (Q_x, Q_y)$:\n",
    "\n",
    "$$\\text{atan2}(Q_y,Q_x)$$\n",
    "\n",
    "Berechnen Sie anschließend einen Korrekturwinkel basierend auf dem Dreieck, das durch die beiden Glieder gebildet wird, und dem Vektor zu $Q$. Diese Korrektur berücksichtigt die Beugung des zweiten Glieds (mit der Länge $L_2$) am Ellbogen mit dem Winkel $\\beta$:\n",
    "\n",
    "$$\\text{atan2}(L_2\\sin⁡(\\beta),L_1+L_2\\cos⁡(\\beta))$$\n",
    "\n",
    "Der Schulterwinkel $\\alpha$ ergibt sich durch Subtraktion der Korrektur von der Gesamtrichtung zu $Q$:\n",
    "$$\\alpha = \\text{atan2}(Q_y, Q_x) - \\text{atan2}(L_2 \\sin(\\beta), L_1 + L_2 \\cos(\\beta))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd08946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_inverse_kinematics(target_GB):\n",
    "    \n",
    "    \"\"\"\n",
    "    put your code here\n",
    "    \"\"\"\n",
    "\n",
    "    return alpha, beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b7fd9",
   "metadata": {},
   "source": [
    "Jetzt können Sie überprüfen, ob Ihre inverse Kinematik korrekt implementiert ist, indem Sie eine Liste mit zwei Werten einfügen. Der erste Wert entspricht der x-Position des Endeffektors, der zweite der y-Position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = ...\n",
    "\n",
    "alpha, beta = robot_inverse_kinematics(point)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "_, _ = robot_draw(ax, alpha, beta, INITIAL_MANIPULABLE_OBJECT_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d56d9",
   "metadata": {},
   "source": [
    "## Aufgabe 2.2 Sicheren Roboterpfad erstellen \n",
    "\n",
    "In diesem Abschnitt definieren Sie den Pfad des Robotergreifers anhand einer Liste von Wegpunkten (**waypoints**). Jeder Wegpunkt ist eine bestimmte $(x, y)$-Koordinate, die der Greifer erreichen muss. Zwischen den von Ihnen angegebenen Wegpunkten wird vom Robotersysten automatisch linear interpoliert.\n",
    "\n",
    "Die Grundidee ist einfach:\n",
    "\n",
    "1. **Wegpunkte zum Objekt definieren**: Sie müssen eine Reihe von Punkten erstellen, die den Robotergreifer **über** das zu greifende Objekt und dann **nach unten** zum Objekt führen.\n",
    "\n",
    "2. **Automatisches Greifen**: Sobald der Greifer die `pick_location` erreicht hat, erkennt das Robotersystem das Objekt automatisch und simuliert das Greifen. Sie müssen keinen Code für die Greifaktion selbst schreiben.\n",
    "\n",
    "3. **Wegpunkte zum Ablagepunkt definieren:** Nach dem Aufnehmen definieren Sie eine weitere Punktsequenz, um den Roboter mit dem Objekt **über** der `place_location` (wo Sie es ablegen möchten) und anschließend **nach unten** zu diesem Punkt zu bewegen. Planen Sie Ihren Weg so, dass Hindernisse vermieden werden.\n",
    "\n",
    "4. **Automatisches Platzieren:** Wenn der Greifer die `place_location` erreicht, simuliert das Robotersystem automatisch das Ablegen des Objekts, und es bleibt dort.\n",
    "\n",
    "Ihre Aufgabe ist es, die `waypoints` mit diesen `[x, y]`-Koordinaten zu definieren. Stellen Sie sich das so vor, als würden Sie den Pfad zeichnen, dem der Greifer folgen soll. Führen Sie anschließend die Funktion `run_pick_and_place_animation(my_waypoints)` aus, um die Animation anzuzeigen.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856821eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "put your code here\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
