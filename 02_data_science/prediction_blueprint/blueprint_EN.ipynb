{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Prediction Model Blueprint\n",
    "\n",
    "Topic: Energy consumption prediction\n",
    "\n",
    "Author: Ananya W.\n",
    "\n",
    "Packages: [pandas](https://pandas.pydata.org/docs/reference/index.html), [scikit-learn (sklearn)](https://scikit-learn.org/stable/api/index.html), [seaborn](https://seaborn.pydata.org/tutorial.html)\n",
    "\n",
    "Files:`blueprint_data_{train/assessment}.csv`\n",
    "\n",
    "Ananya's work in this document is divided into 5 phases (steps):\n",
    "1. Data analysis\n",
    "2. Data cleansing\n",
    "3. Feature engineering\n",
    "4. Data set splitting\n",
    "5. Model training and testing\n",
    "6. Evaluation and encapsulation of the results\n",
    "   \n",
    "Ananya has also left you a message at the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Data analysis\n",
    "First, we focus on a brief exploratory data analysis to obtain an initial overview."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Importing the data set\n",
    "\n",
    "Importing the data set and outputting dimensions, columns and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:10.409233Z",
     "start_time": "2025-06-26T09:12:10.384142Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv('blueprint_data_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Output of basic information on the data record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:10.417642Z",
     "start_time": "2025-06-26T09:12:10.410453Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The `energy_joule` column contains zero values that must be treated. This is dealt with in part 2 (data cleansing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Use the `describe()` method to output the value ranges and simple column statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:10.435479Z",
     "start_time": "2025-06-26T09:12:10.418658Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The column `location_id` has variance 0 (all entries have the value 1). The column is removed in part 2 (data cleansing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Output of the first lines of the data record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:10.443930Z",
     "start_time": "2025-06-26T09:12:10.436548Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Plotting of simple visualizations\n",
    "\n",
    "The external library `seaborn` is used for visualization.\n",
    "\n",
    "Display of histograms for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:11.724730Z",
     "start_time": "2025-06-26T09:12:10.445011Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for col in dataframe.columns:\n",
    "    print(col)\n",
    "    plt.figure(1, figsize=(5,5))\n",
    "    sns.histplot(dataframe, x=col, discrete=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "The third histogram shows that there are two types of robots, namely “Robot1” and “Robot2”. These are encoded as strings and must be encoded as numeric values as most machine learning models only accept numeric input. This is covered in Part 3 (Feature Engineering)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Pairwise visualization of the distributions of two columns.\n",
    "\n",
    "The row for the prediction target `energy_joule` is particularly relevant here in order to derive an estimate of which features influence energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.525071Z",
     "start_time": "2025-06-26T09:12:11.725951Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The feature columns `distance`, `number_of_turns`, `additional_cargo` and `rush_level` appear to correlate with energy consumption and are therefore retained (as input for the regression model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 2. Data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "In this part, we first deal with the zero and NaN values contained in the ‘energy_joule’ column. We decide to simply delete the corresponding rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.529066Z",
     "start_time": "2025-06-26T09:12:15.525071Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.546235Z",
     "start_time": "2025-06-26T09:12:15.531821Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The entries in the `commissioner` column are not relevant for the robot's energy consumption. \n",
    "This suspicion is suggested by the logical understanding of the problem and is confirmed by the above visualization.\n",
    "\n",
    "Furthermore, the column `localtion_id` has no variance.\n",
    "\n",
    "The columns are removed from the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.550870Z",
     "start_time": "2025-06-26T09:12:15.546235Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns=[\"commissioner\", \"location_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "As observed in part 1, the `robot` column describes the type of robot (`robot1` or `robot2`) in string format. The entries in this column can be ordinally encoded as integers; `Robot1` is replaced with `1` and `Robot2` is replaced with `2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.558413Z",
     "start_time": "2025-06-26T09:12:15.552513Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_string_robot_to_numeric(str_robot):\n",
    "    if str_robot == \"Robot1\":\n",
    "        return 1\n",
    "    elif str_robot == \"Robot2\":\n",
    "        return 2\n",
    "    else:\n",
    "        print(\"str_robot must be either Robot1 or Robot2\")\n",
    "        print(\"Returning None\")\n",
    "        return None\n",
    "        \n",
    "dataframe[\"robot\"] = dataframe[\"robot\"].map(convert_string_robot_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.569631Z",
     "start_time": "2025-06-26T09:12:15.559486Z"
    }
   },
   "outputs": [],
   "source": [
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Instead of the ordinal encoding performed, you can also create binary variables that refer to `Robot1` and `Robot2`. This is called one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. Dataset splitting\n",
    "\n",
    "In order to be able to evaluate the results of a model properly, we first split our training data into two parts:\n",
    "The first part is actually used for model training, and the second part is reserved for evaluating (testing) the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.740239Z",
     "start_time": "2025-06-26T09:12:15.570192Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(dataframe, test_size=0.3, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5. Model training and testing\n",
    "\n",
    "We train different models on the training dataset and evaluate them using the split test data.\n",
    "\n",
    "We will look at the following models:\n",
    "\n",
    "* Linear regression\n",
    "* Polynomial regression\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "\n",
    "Linear and polynomial regression assume monotonic relationships between the features and the value to be predicted. \n",
    "We must therefore consider for each input whether this feature fulfills this requirement or whether it can be preprocessed accordingly.\n",
    "The Scikit-Learn documentation on [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and [Polynomial Features](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) will also help you here.\n",
    "The [Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/linear_model.html) provides additional information.\n",
    "\n",
    "Tree-based models (e.g. decision tree and random forest) can usually work well with most features in their raw form and, unlike other methods, are not dependent on (approximately) uniform scaling or variances.\n",
    "Individual decision trees are rarely used as a forecasting model in practice, as they often do not generalize very well, i.e. they often do not achieve very good results on unseen data.\n",
    "Instead, so-called random forests are often used, which consist of a large number of trees trained on parts of the data set that contribute equally to the prediction result.\n",
    "Further information on this can be found in the [Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/tree.html#) and the [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html).\n",
    "\n",
    "We train and evaluate all four model types on the prepared data and then select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.745622Z",
     "start_time": "2025-06-26T09:12:15.741299Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "target_column = \"energy_joule\"\n",
    "feature_columns = dataframe.columns.drop(target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.751617Z",
     "start_time": "2025-06-26T09:12:15.746750Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "mse_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### 1) Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.806998Z",
     "start_time": "2025-06-26T09:12:15.752684Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lin_reg = LinearRegression()\n",
    "model_lin_reg.fit(train_df[feature_columns], train_df[target_column])\n",
    "\n",
    "predictions = model_lin_reg.predict(test_df[feature_columns])\n",
    "\n",
    "lin_reg_mse = mean_squared_error(test_df[target_column], predictions)\n",
    "\n",
    "mse_dict[\"Linear Regression\"] = lin_reg_mse\n",
    "print(f\"MSE: {lin_reg_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### 2) Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.818332Z",
     "start_time": "2025-06-26T09:12:15.807059Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "preprocessor_pol_reg = PolynomialFeatures(degree=2)\n",
    "train_features_poly = preprocessor_pol_reg.fit_transform(train_df[feature_columns])\n",
    "model_pol_reg = LinearRegression()\n",
    "model_pol_reg.fit(train_features_poly, train_df[target_column])\n",
    "\n",
    "test_features_poly = preprocessor_pol_reg.transform(test_df[feature_columns])\n",
    "predictions = model_pol_reg.predict(test_features_poly)\n",
    "pol_reg_mse = mean_squared_error(test_df[target_column], predictions)\n",
    "\n",
    "mse_dict[\"Polynomial Regression\"] = pol_reg_mse\n",
    "print(f\"MSE: {pol_reg_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### 3) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.866825Z",
     "start_time": "2025-06-26T09:12:15.819416Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_tree = DecisionTreeRegressor()\n",
    "model_tree.fit(train_df[feature_columns], train_df[target_column])\n",
    "\n",
    "predictions = model_tree.predict(test_df[feature_columns])\n",
    "tree_mse = mean_squared_error(test_df[target_column], predictions)\n",
    "\n",
    "mse_dict[\"Decision Tree\"] = tree_mse\n",
    "print(f\"MSE: {tree_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### 4) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.464958Z",
     "start_time": "2025-06-26T09:12:15.867829Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_forest = RandomForestRegressor(n_estimators=100)\n",
    "model_forest.fit(train_df[feature_columns], train_df[target_column])\n",
    "\n",
    "predictions = model_forest.predict(test_df[feature_columns])\n",
    "forest_mse = mean_squared_error(test_df[target_column], predictions)\n",
    "\n",
    "mse_dict[\"Random Forest\"] = forest_mse\n",
    "print(f\"MSE: {forest_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.470766Z",
     "start_time": "2025-06-26T09:12:16.466031Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for key, value in mse_dict.items():\n",
    "    print(f\"{key:25s}\\t{value:>8.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The best results (lowest MSE) were achieved with the polynomial regression model. This is recommended for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 6. Evaluation and encapsulation of the results\n",
    "#### Creation of a function to evaluate an unseen data set\n",
    "\n",
    "We now implement a function that executes and evaluates the model on unseen datasets in the identical format.\n",
    "The best results were obtained with polynomial regression, so this model is used in the function.\n",
    "\n",
    "The function is then executed on the existing test dataset `blueprint_data_assessment.csv`, and the results are displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "First, the data pre-processing steps carried out above are summarized in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.486787Z",
     "start_time": "2025-06-26T09:12:16.471389Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns=[\"location_id\", \"commissioner\"])\n",
    "    df[\"robot\"] = df[\"robot\"].map(convert_string_robot_to_numeric) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We then write a function to execute the previously trained model on a preprocessed data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.493813Z",
     "start_time": "2025-06-26T09:12:16.487844Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_model(df):\n",
    "    features = preprocessor_pol_reg.transform(df[feature_columns])\n",
    "    predictions = model_pol_reg.predict(features)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We now combine the reading, preprocessing, prediction and calculation of the error in a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.500668Z",
     "start_time": "2025-06-26T09:12:16.494897Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_and_evaluate_on_dataset(dataset_path):\n",
    "    dataset_df = pd.read_csv(dataset_path)\n",
    "    dataset_proc = preprocess_data(dataset_df)\n",
    "    dataset_pred = run_model(dataset_proc)\n",
    "    \n",
    "    error_mse = mean_squared_error(dataset_proc[target_column], dataset_pred)\n",
    "    error_mape = mean_absolute_percentage_error(dataset_proc[target_column], dataset_pred)\n",
    "    \n",
    "    return error_mse, error_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We perform the above steps on the test data set using a single function call and output the results to the console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.519526Z",
     "start_time": "2025-06-26T09:12:16.501776Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "file = 'blueprint_data_assessment.csv'\n",
    "error_mse, error_mape = run_and_evaluate_on_dataset(file)\n",
    "print(f\"Evaluationsergebnisse der Daten {file}\")\n",
    "print(f\"{'Error MSE':30s} {error_mse:>10.3f}\")\n",
    "print(f\"{'Error MAPE':30s} {100*error_mape:>10.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "An average percentage deviation of 5.17 % in the prediction of energy consumption is achieved on the assessment data set. A solid result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### A message from Ananya:\n",
    "\n",
    "We are totally excited to see what the long-promised dataset with the records of the productive system will look like!\n",
    "Hopefully our approaches and models can also be used for this new data.\n",
    "\n",
    "Unfortunately, we will no longer be on the project team to analyze the new dataset ourselves.\n",
    "Whoever takes over the project, we hope that the analyses and experiments we have already conducted will help our successors to solve this exciting problem.\n",
    "\n",
    "\n",
    "All the best and good luck!\n",
    "\n",
    "Ananya W."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
