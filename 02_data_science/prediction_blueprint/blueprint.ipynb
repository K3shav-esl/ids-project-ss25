{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Prediction Model Blueprint\n",
    "\n",
    "Thema: Energie-Verbrauchs-Prognose\n",
    "\n",
    "Autorin: Ananya W.\n",
    "\n",
    "Pakete: [pandas](https://pandas.pydata.org/docs/reference/index.html), [scikit-learn (sklearn)](https://scikit-learn.org/stable/api/index.html), [seaborn](https://seaborn.pydata.org/tutorial.html)\n",
    "\n",
    "Dateien:`blueprint_data_{train/assessment}.csv`\n",
    "\n",
    "Die Arbeiten von Ananya in diesem Dokument gliedern sich in 5 Phasen (Schritte):\n",
    "1. Datenanalyse\n",
    "2. Datenbereinigung\n",
    "3. Feature Engineering\n",
    "4. Datensatz-Splitting\n",
    "5. Modell-Training und -Test\n",
    "6. Evaluation und Kapselung der Ergebnisse\n",
    "   \n",
    "Außerdem hat Ihnen Ananya ganz am Ende des Notebooks noch eine Nachricht hinterlassen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Datenanalyse\n",
    "Zunächst fokussieren wir uns auf eine kurze explorative Datenanalyse, um einen ersten Überblick zu erhalten. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Einlesen des Datensatzes\n",
    "\n",
    "Einlesen des Datensatzes und Ausgabe von Dimension, Spalten und Statistiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:10.409233Z",
     "start_time": "2025-06-26T09:12:10.384142Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv('blueprint_data_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Ausgabe grundlegender Informationen zum Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:10.417642Z",
     "start_time": "2025-06-26T09:12:10.410453Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Die Spalte `energy_joule` enthält null-Werte die behandelt werden müssen. Das wird in Teil 2 (Datenbereinigung) behandelt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Verwenden der Methode `describe()` zur Ausgabe der Wertebereiche und einfacher Statistiken der Spalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:10.435479Z",
     "start_time": "2025-06-26T09:12:10.418658Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Die Spalte `location_id` hat Varianz 0 (alle Einträge haben den Wert 1). Die Spalte wird in Teil 2 (Datenbereinigung) entfernt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Ausgabe der ersten Zeilen des Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:10.443930Z",
     "start_time": "2025-06-26T09:12:10.436548Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Erstellung einfacher Visualisierungen\n",
    "\n",
    "Zur Visualisierung wird die externe Bibliothek `seaborn` verwendet.\n",
    "\n",
    "Anzeige von Histogrammen für jede Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:11.724730Z",
     "start_time": "2025-06-26T09:12:10.445011Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for col in dataframe.columns:\n",
    "    print(col)\n",
    "    plt.figure(1, figsize=(5,5))\n",
    "    sns.histplot(dataframe, x=col, discrete=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Das dritte Histogramm zeigt, dass es zwei Arten von Robotern gibt, nämlich „Robot1“ und „Robot2“. Diese sind als Zeichenketten (strings) kodiert und müssen als numerische Werte kodiert werden, da die meisten Modelle für maschinelles Lernen nur numerische Eingaben akzeptieren. Dies wird in Teil 3 (Feature Engineering) behandelt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Paarweise Visualisierung der Verteilungen zweier Spalten.\n",
    "\n",
    "Hierbei ist insbesondere die Zeile zum Vorhersageziel `energy_joule` relevant, um eine Einschätzung abzuleiten, welche Features des Energieverbrauch beeinflussen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.525071Z",
     "start_time": "2025-06-26T09:12:11.725951Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Die Feature-Spalten `distance`, `number_of_turns`, `additional_cargo` und `rush_level` scheinen mit dem Energieverbrauch zu korrelieren und werden daher beibehalten (als Input für das Regressions-Modell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 2. Datenbereinigung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "In diesem Teil, Behandeln wir zuerst die null-Werte, die die Spalte`energy_joule` enthält. Wir entscheiden uns hier für einfaches Löschen der entsprechenden Zeilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.529066Z",
     "start_time": "2025-06-26T09:12:15.525071Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.546235Z",
     "start_time": "2025-06-26T09:12:15.531821Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Die Einträge der Spalte `commissioner` sind nicht relevant für den Energieverbrauch des Roboters. \n",
    "Den Verdacht legt das logische Verständnis des Problems nahe und er bestätigt sich durch die obige Visualisierung.\n",
    "\n",
    "Außerdem, hat die Spalte `localtion_id` keine Varianz.\n",
    "\n",
    "Die Spalten werden aus dem Datensatz entfernt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.550870Z",
     "start_time": "2025-06-26T09:12:15.546235Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns=[\"commissioner\", \"location_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Wie in Teil 1 beobachtet, beschreibt die Spalte `robot` den Typ des Roboters (`Robot1` oder `Robot2`) in String-Format. Die Einträge dieser Spalte können ordinal als Integers encodiert. `Robot1` wird mit `1` ersetzt und `Robot2` wird mit `2` ersetzt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.558413Z",
     "start_time": "2025-06-26T09:12:15.552513Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_string_robot_to_numeric(str_robot):\n",
    "    if str_robot == \"Robot1\":\n",
    "        return 1\n",
    "    elif str_robot == \"Robot2\":\n",
    "        return 2\n",
    "    else:\n",
    "        print(\"str_robot must be either Robot1 or Robot2\")\n",
    "        print(\"Returning None\")\n",
    "        return None\n",
    "        \n",
    "dataframe[\"robot\"] = dataframe[\"robot\"].map(convert_string_robot_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.569631Z",
     "start_time": "2025-06-26T09:12:15.559486Z"
    }
   },
   "outputs": [],
   "source": [
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Man kann statt der durchgeführten ordinalen Encodierung auch binäre Variablen erstellen, die sich auf `Robot1` und `Robot2` beziehen. Das nennt man One-Hot Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. Datensatz-Splitting\n",
    "\n",
    "Um die Ergebnisse eines Modells sauber evaluieren zu können, teilen wir unsere Trainingsdaten zunächst in zwei Teile auf:\n",
    "Der erste Teil wird tatsächlich für das Modell-Training verwendet, der zweite Teil wird für die Evaluation (Test) des Modells vorbehalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.740239Z",
     "start_time": "2025-06-26T09:12:15.570192Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(dataframe, test_size=0.3, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5. Modell-Training und -Test\n",
    "\n",
    "Wir trainieren verschiedene Modelle auf dem Trainings-Datensatz und evaluieren diese mit Hilfe der abgespaltenen Testdaten.\n",
    "\n",
    "Die folgenden Modelle wollen wir betrachten:\n",
    "\n",
    "* Lineare Regression\n",
    "* Polynomiale Regression\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "\n",
    "Lineare und Polynomiale Regression nehmen dabei monotone Zusammenhänge zwischen den Features und dem vorherzusagenden Wert an. \n",
    "Wir müssen also bei jedem Input überlegen, ob dieses Feature diese Anforderung erfüllt oder ggf. entsprechend vorverarbeitet werden kann.\n",
    "Hier hilft Ihnen auch die Dokumentation von Scikit-Learn zu [Linearer Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) und [Polynomialen Features](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html).\n",
    "Der [Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/linear_model.html) liefert hier noch zusätzliche Hinweise. \n",
    "\n",
    "Baum-basierte Modelle (z.B. Decision Tree und Random Forest) können in der Regel mit den meisten Features in Rohform gut arbeiten und sind, im Gegensatz zu anderen Verfahren, nicht auf (annähernd) einheitliche Skalierungen oder Varianzen angewiesen.\n",
    "Einzelne Entscheidungsbäume (Decision Tree) werden in der Praxis selten als Prognosemodell eingesetzt, da Sie oft nicht sehr gut generalisieren, d.h. auf ungesehenen Daten oft keine sehr guten Ergebnisse erzielen.\n",
    "Stattdessen verwendet man oft sogenannte Random Forests, welche aus sehr vielen, auf Datensatzteilen trainierten Bäumen bestehen, die in gleichen Teilen zum Vorhersage-Ergebnis beitragen.\n",
    "Nähere Informationen hierzu können dem [Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/tree.html#) und der [Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) entnommen werden.\n",
    "\n",
    "Wir trainieren und evaluieren alle vier Modelltypen auf den vorbereiteten Daten und wählen anschließend das beste Modell aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.745622Z",
     "start_time": "2025-06-26T09:12:15.741299Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "target_column = \"energy_joule\"\n",
    "feature_columns = dataframe.columns.drop(target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.751617Z",
     "start_time": "2025-06-26T09:12:15.746750Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "mse_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### 1) Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.806998Z",
     "start_time": "2025-06-26T09:12:15.752684Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lin_reg = LinearRegression()\n",
    "model_lin_reg.fit(train_df[feature_columns], train_df[target_column])\n",
    "\n",
    "predictions = model_lin_reg.predict(test_df[feature_columns])\n",
    "\n",
    "lin_reg_mse = mean_squared_error(test_df[target_column], predictions)\n",
    "\n",
    "mse_dict[\"Linear Regression\"] = lin_reg_mse\n",
    "print(f\"MSE: {lin_reg_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### 2) Polynomiale Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.818332Z",
     "start_time": "2025-06-26T09:12:15.807059Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "preprocessor_pol_reg = PolynomialFeatures(degree=2)\n",
    "train_features_poly = preprocessor_pol_reg.fit_transform(train_df[feature_columns])\n",
    "model_pol_reg = LinearRegression()\n",
    "model_pol_reg.fit(train_features_poly, train_df[target_column])\n",
    "\n",
    "test_features_poly = preprocessor_pol_reg.transform(test_df[feature_columns])\n",
    "predictions = model_pol_reg.predict(test_features_poly)\n",
    "pol_reg_mse = mean_squared_error(test_df[target_column], predictions)\n",
    "\n",
    "mse_dict[\"Polynomial Regression\"] = pol_reg_mse\n",
    "print(f\"MSE: {pol_reg_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### 3) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:15.866825Z",
     "start_time": "2025-06-26T09:12:15.819416Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_tree = DecisionTreeRegressor()\n",
    "model_tree.fit(train_df[feature_columns], train_df[target_column])\n",
    "\n",
    "predictions = model_tree.predict(test_df[feature_columns])\n",
    "tree_mse = mean_squared_error(test_df[target_column], predictions)\n",
    "\n",
    "mse_dict[\"Decision Tree\"] = tree_mse\n",
    "print(f\"MSE: {tree_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### 4) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.464958Z",
     "start_time": "2025-06-26T09:12:15.867829Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_forest = RandomForestRegressor(n_estimators=100)\n",
    "model_forest.fit(train_df[feature_columns], train_df[target_column])\n",
    "\n",
    "predictions = model_forest.predict(test_df[feature_columns])\n",
    "forest_mse = mean_squared_error(test_df[target_column], predictions)\n",
    "\n",
    "mse_dict[\"Random Forest\"] = forest_mse\n",
    "print(f\"MSE: {forest_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.470766Z",
     "start_time": "2025-06-26T09:12:16.466031Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for key, value in mse_dict.items():\n",
    "    print(f\"{key:25s}\\t{value:>8.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Die besten Ergebnisse (geringster MSE) wurde mit den Modell der polynomialen Regression erzielt. Dieses wird für die weitere Verwendung empfohlen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 6. Evaluation und Kapselung der Ergebnisse\n",
    "#### Erstellung einer Funktion zur Evaluation eines ungesehenen Datensatzes\n",
    "\n",
    "Wir implementieren nun eine Funktion, welche das Modell auf ungesehenen Datensätzes in identischem Format ausführt und evaluiert.\n",
    "Die besten Ergebnisse wurden mit der polynomialen Regression erzielt, daher wird dieses Modell in der Funktion verwendet.\n",
    "\n",
    "Die Funktion wird anschließend auf dem vorhandenen Test-Datensatz `'blueprint_data_assessment.csv'` ausgeführt und die Ergebnisse angezeigt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Zunächst werden die oben durchgeführten Datenvorverarbeitungs-Schritte in einer Funktion zusammengefasst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.486787Z",
     "start_time": "2025-06-26T09:12:16.471389Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns=[\"location_id\", \"commissioner\"])\n",
    "    df[\"robot\"] = df[\"robot\"].map(convert_string_robot_to_numeric) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Anschließend schreiben wir eine Funktion zur Ausführung des zuvor trainierten Modells auf einem vorverarbeiteten Datensatz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.493813Z",
     "start_time": "2025-06-26T09:12:16.487844Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_model(df):\n",
    "    features = preprocessor_pol_reg.transform(df[feature_columns])\n",
    "    predictions = model_pol_reg.predict(features)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Wir fassen nun das Einlesen, die Vorverarbeitung, die Prädiktion, sowie die Berechnung des Fehlers in einer einzigen Funktion zusammen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.500668Z",
     "start_time": "2025-06-26T09:12:16.494897Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_and_evaluate_on_dataset(dataset_path):\n",
    "    dataset_df = pd.read_csv(dataset_path)\n",
    "    dataset_proc = preprocess_data(dataset_df)\n",
    "    dataset_pred = run_model(dataset_proc)\n",
    "    \n",
    "    error_mse = mean_squared_error(dataset_proc[target_column], dataset_pred)\n",
    "    error_mape = mean_absolute_percentage_error(dataset_proc[target_column], dataset_pred)\n",
    "    \n",
    "    return error_mse, error_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Wir führen die oben genannten Schritte auf dem Testdatensatz mit Hilfe eines einzelnen Funktionsaufrufes durch und geben die Ergebnisse auf der Konsole aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T09:12:16.519526Z",
     "start_time": "2025-06-26T09:12:16.501776Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "file = 'blueprint_data_assessment.csv'\n",
    "error_mse, error_mape = run_and_evaluate_on_dataset(file)\n",
    "print(f\"Evaluationsergebnisse der Daten {file}\")\n",
    "print(f\"{'Error MSE':30s} {error_mse:>10.3f}\")\n",
    "print(f\"{'Error MAPE':30s} {100*error_mape:>10.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Es wird eine mittlere prozentuale Abweichung der Vorhersage des Energieverbrauchs von 5,17 % auf dem assessment-Datensatz erreicht. Ein solides Ergebnis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Eine Nachricht von Ananya:\n",
    "\n",
    "Wir sind total gespannt wie der lange versprochene Datensatz mit den Aufzeichnungen des Produktiv-Systems aussehen wird!\n",
    "Hoffentlich können unsere Ansätze und Modelle auch für diese neuen Daten verwendet werden.\n",
    "\n",
    "Leider werden wir nicht mehr im Projektteam sein, um den neuen Datensatz selbst zu analysieren.\n",
    "Wer auch immer das Projekt dann bearbeiten mag - wir hoffen, unsere bereits durchgeführten Analysen und Experimente helfen unseren Nachfolgern bei der Lösung dieses spannenden Problems.\n",
    "\n",
    "\n",
    "Alles Gute und viel Erfolg!\n",
    "\n",
    "Ananya W.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
